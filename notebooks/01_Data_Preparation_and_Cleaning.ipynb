{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Preparation and Cleaning",
   "id": "3fd62dbd989138c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. SETUP & IMPORTS",
   "id": "2782738e0f315688"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "id": "3101846636aa5aa1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "id": "5ca641dba07249e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. DATEN LADEN",
   "id": "d124f11bf531251"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_dir = Path.cwd()\n",
    "data_file = 'OECD.WISE.WDP,DSD_HSL@DF_HSL_CWB,+all.csv'\n",
    "candidates = [\n",
    "    base_dir / 'data' / data_file,\n",
    "    base_dir.parent / 'data' / data_file,\n",
    "]\n",
    "data_path = next((p for p in candidates if p.exists()), None)\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError(f\"Datei nicht gefunden. Versucht wurden: {candidates}\")\n",
    "\n",
    "print(f\"Lade Daten von: {data_path}\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(\"Daten erfolgreich geladen!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"FEHLER: Datei nicht gefunden. Prüfe den Pfad oder verschiebe die CSV in einen 'data' Ordner.\")\n"
   ],
   "id": "e6aeb623bb63b8a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. ERSTE INSPEKTION",
   "id": "59ba97cb0a585980"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"Dimensionen: {df.shape}\")\n",
    "print(df.head(3))\n",
    "print(df.info())"
   ],
   "id": "114857c785e48b43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. DATEN BEREINIGUNG",
   "id": "f366c22947f77a1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cols_to_drop = [\n",
    "    'STRUCTURE', 'STRUCTURE_ID', 'STRUCTURE_NAME', 'ACTION', \n",
    "    'REF_AREA',      # Wir haben 'Reference area'\n",
    "    'MEASURE',       # Wir haben 'Measure'\n",
    "    'UNIT_MEASURE',  # Wir haben 'Unit of measure'\n",
    "    'AGE',           # Wir haben 'Age'\n",
    "    'SEX',           # Wir haben 'Sex'\n",
    "    'EDUCATION_LEV', # Wir haben 'Education level'\n",
    "    'DOMAIN',        # Wir haben 'Domain'\n",
    "    'OBS_STATUS', 'Observation status', \n",
    "    'UNIT_MULT', 'Unit multiplier', \n",
    "    'DECIMALS', 'Decimals', \n",
    "    'BASE_PER', 'Base period',\n",
    "    'Observation value', # War leer, wir nutzen OBS_VALUE\n",
    "    'Time period' # Ist oft leer oder doppelt, wir nutzen TIME_PERIOD\n",
    "]\n",
    "\n",
    "# Nur existierende Spalten droppen\n",
    "df_clean = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors='ignore')\n",
    "\n",
    "# Spaltennamen normalisieren\n",
    "df_clean.columns = [c.lower().replace(' ', '_') for c in df_clean.columns]\n",
    "df_clean.rename(columns={'obs_value': 'value', 'time_period': 'year'}, inplace=True)\n",
    "\n",
    "print(\"\\n--- Spalten nach Bereinigung ---\")\n",
    "print(df_clean.columns.tolist())"
   ],
   "id": "2cff63d6b2077de5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. UMGANG MIT FILTERN & DUPLIKATEN",
   "id": "baeda69f72a502aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\nVerfügbare Measures (Top 10):\")\n",
    "print(df_clean['measure'].unique()[:10])"
   ],
   "id": "39b62437cce305c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Sortieren nach Jahr, damit 'last' wirklich das aktuellste ist\n",
    "df_clean = df_clean.sort_values('year')\n",
    "\n",
    "#Einheiten definieren\n",
    "group_cols = ['reference_area', 'measure', 'sex', 'age', 'education_level', 'domain']\n",
    "\n",
    "df_time = df_clean.copy()\n",
    "\n",
    "#Filtern auf 1 Jahr, um Unabhängigkeit zu wahren\n",
    "df_latest = df_clean.drop_duplicates(subset=group_cols, keep='last')\n",
    "\n",
    "print(f\"Datensatz für Zeitreihen (df_time): {len(df_time)} Zeilen\")\n",
    "print(f\"Datensatz für Hypothesentests (df_latest): {len(df_latest)} Zeilen\")"
   ],
   "id": "b70838ad08d97a53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. MISSING VALUES HANDLING",
   "id": "bf22d03722aa9182"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Analyse fehlender Werte vor dem Bereinigen:\")\n",
    "\n",
    "missing_counts = df_clean.isnull().sum()\n",
    "print(missing_counts[missing_counts > 0])\n",
    "\n",
    "# Welche Länder haben am meisten Datenlücken?\n",
    "missing_by_country = df_clean.isnull().groupby(df_clean['reference_area']).sum().sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "# Nur plotten, wenn es tatsächlich fehlende Werte gibt\n",
    "if missing_by_country[missing_by_country > 0].shape[0] > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_by_country[missing_by_country > 0].head(10).plot(kind='bar', color='salmon')\n",
    "    plt.title(\"Top 10 Länder mit den meisten fehlenden Werten\")\n",
    "    plt.ylabel(\"Anzahl fehlender Datenpunkte\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Keine fehlenden Werte nach Ländern gefunden.\")\n",
    "\n",
    "# Beide Datensätze von leeren Werten in der Zielvariable bereinigen\n",
    "df_time = df_time.dropna(subset=['value'])\n",
    "df_latest = df_latest.dropna(subset=['value'])\n",
    "\n"
   ],
   "id": "3cc1ab458b0d4b98"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Analyse der fehlenden Werte:\n",
    "\n",
    "Der Output zeigt, dass in den für die Analyse relevanten Spalten keine fehlenden Werte (Missing Values) vorhanden sind. Die missing_counts Series ist leer.\n",
    "\n",
    "Da der Datensatz vollständig ist (0% Missingness), entfällt die Notwendigkeit, zwischen den Mechanismen MCAR (Missing Completely At Random), MAR (Missing At Random) oder MNAR (Missing Not At Random) zu unterscheiden.\n",
    "\n",
    "=> Es liegt kein Bias durch fehlende Daten vor (z. B. dass ärmere Länder seltener Daten berichten würden = MNAR). Wir können dropna() formal ausführen (es löscht nichts) und mit dem vollständigen Datensatz weiterarbeiten, was die interne Validität der Studie stärkt.\n",
    "\n",
    "Trtozdem könnte bei uns ein **Sampling** oder **Selection Bias** auftreten. \n",
    "\n",
    "Theoretisch wollen wir Aussagen über den Zusammenhang von Wohlstand und Sicherheit für *alle* Länder treffen (Population). Unser Datensatz enthält jedoch fast ausschließlich **OECD-Länder**. Die OECD besteht primär aus westlichen Industrienationen mit hohem Einkommen und stabilen demokratischen Strukturen. Länder des globalen Südens, Schwellenländer und Krisenregionen sind stark unterrepräsentiert.\n",
    "\n",
    "Unsere Ergebnisse leiden somit unter einem **Selection Bias**. Gefundene Korrelationen (z.B. \"Geld macht sicher\") gelten streng genommen nur für den Kontext entwickelter Industrienationen (\"Deckeneffekt\" des Sicherheitsgefühls). **Eine Generalisierung auf die gesamte Weltbevölkerung ist statistisch nicht zulässig.**"
   ],
   "id": "6de9f192c05e7698"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. SPEICHERN",
   "id": "22fcb8b7afe7b05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "df_time.to_csv(base_dir.parent / 'data' / 'oecd_full_time_series.csv', index=False)\n",
    "df_latest.to_csv(base_dir.parent / 'data' / 'oecd_snapshot_latest.csv', index=False)\n",
    "\n",
    "print(\"Beide Datensätze gespeichert.\")"
   ],
   "id": "63039cc384307442"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Für die Analyse haben wir **zwei Versionen des Datensatzes** erstellt:\n",
    "\n",
    "**oecd_full_time_series.csv** : Enthält alle historischen Daten. Wird verwendet für deskriptive Zeitreihenanalysen (Trendentwicklung).\n",
    "\n",
    "**oecd_snapshot_latest.csv** : Enthält nur den jeweils aktuellsten Datenpunkt pro Land und Kategorie. Wird verwendet für induktive Statistik (Hypothesentests, Korrelationen), um die statistische Annahme der Unabhängigkeit der Beobachtungen zu wahren und Pseudoreplikation durch wiederholte Messungen desselben Landes zu vermeiden."
   ],
   "id": "3cb549844ad08cd8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
