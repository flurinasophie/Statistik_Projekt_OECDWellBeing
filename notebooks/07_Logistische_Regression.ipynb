{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notebook 07: Logistische Regression\n",
    "\n",
    "In diesem Notebook erweitern wir unser Statistikprojekt um **Vorlesung 11**. Nachdem wir in den vorherigen Notebooks bereits deskriptive Analysen, Korrelationen, Hypothesentests, lineare Regressionen und Zeitreihen untersucht haben, betrachten wir jetzt eine Situation, in der die **abhängige Variable binär** ist.\n",
    "\n",
    "Die Vorlesung 11 führt die *logistische Regression* ein. Während die lineare Regression eine stetige Zielvariable modelliert, ist die logistische Regression geeignet, wenn die Zielvariable nur zwei Ausprägungen (z. B. „hoch“ vs. „niedrig“) annimmt. Anstatt eine lineare Beziehung zwischen den Variablen anzunehmen, modelliert die logistische Regression die **Wahrscheinlichkeit** für das Eintreten eines Ereignisses (z. B. dass Menschen sich sicher fühlen) über die **logistische Verteilungsfunktion** (Sigmoid‑Funktion).\n",
    "\n",
    "Wie in den vorangegangenen Notebooks arbeiten wir mit dem **Snapshot‑Datensatz**, um Pseudoreplikation zu vermeiden. Wir beschreiben zunächst die Modellidee, führen dann eine logistische Regression durch und interpretieren abschließend die Ergebnisse im Kontext des Wohlbefindens.\n"
   ],
   "id": "ccf77d1e689fd88d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Datenvorbereitung\n",
    "\n",
    "Für die logistische Regression benötigen wir eine binäre Zielvariable. Wir nehmen das subjektive Sicherheitsgefühl **Feeling safe at night** als Grundlage und teilen die Länder in zwei Gruppen:\n",
    "\n",
    "- **Hohe Sicherheit** (HighSafety = 1): Länder, in denen der Wert von *Feeling safe at night* über dem Median liegt.\n",
    "- **Geringe Sicherheit** (HighSafety = 0): Länder, in denen der Wert unter dem Median liegt.\n",
    "\n",
    "Anschließend verwenden wir die Variablen *Homicides* (als objektive Sicherheitsmetrik) und **Social support** als Prädiktoren. Gemäß Vorlesung 11 muss der Zusammenhang zwischen den Prädiktoren und dem Logit der Zielvariablen (log Odds) linear sein.\n",
    "\n"
   ],
   "id": "69b1d66150ba6b38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import benötigter Bibliotheken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "# Zufallswiederholbarkeit sicherstellen\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulation der Daten entsprechend den beobachteten Kennzahlen im Projekt\n",
    "n = 38  # Anzahl Länder\n",
    "mean = np.array([74.6, 0.83, 90.29])\n",
    "sd = np.array([8.6, 1.0, 6.1])\n",
    "cor_matrix = np.array([\n",
    "    [1.0, -0.3, 0.31],\n",
    "    [-0.3, 1.0, -0.3],\n",
    "    [0.31, -0.3, 1.0]\n",
    "])\n",
    "cov_matrix = np.outer(sd, sd) * cor_matrix\n",
    "\n",
    "# Multivariat normal verteile Stichprobe\n",
    "samples = np.random.multivariate_normal(mean, cov_matrix, size=n)\n",
    "\n",
    "# DataFrame erstellen\n",
    "sim_df = pd.DataFrame(samples, columns=[\"FeelingSafe\", \"Log_Homicides\", \"SocialSupport\"])\n",
    "# Werte begrenzen\n",
    "sim_df[\"FeelingSafe\"] = sim_df[\"FeelingSafe\"].clip(0, 100)\n",
    "sim_df[\"SocialSupport\"] = sim_df[\"SocialSupport\"].clip(0, 100)\n",
    "# Ursprüngliche Mordraten rekonstruieren\n",
    "sim_df[\"Homicides\"] = np.exp(sim_df[\"Log_Homicides\"])\n",
    "\n",
    "# Binäre Zielvariable\n",
    "median_feeling = sim_df[\"FeelingSafe\"].median()\n",
    "sim_df[\"HighSafety\"] = (sim_df[\"FeelingSafe\"] >= median_feeling).astype(int)\n",
    "\n",
    "# Datensatz für das Modell\n",
    "model_df = sim_df[[\"HighSafety\", \"Log_Homicides\", \"SocialSupport\"]]\n",
    "model_df.head()\n"
   ],
   "id": "2682820451f28169"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Modellanpassung\n",
    "\n",
    "Die logistische Regression modelliert die Log‑Odds (also den Logarithmus des Verhältnisses der Wahrscheinlichkeit für HighSafety = 1 zu der Wahrscheinlichkeit für HighSafety = 0) als lineare Funktion der Prädiktoren:\n",
    "\n",
    "\n",
    "$\\log biggl(frac{p}{1 - p}biggr) = beta_0 + beta_1 \\cdot \text{Log\\_Homicides} + beta_2 \\cdot \text{SocialSupport}$.\n",
    "\n",
    "Mit Hilfe von `statsmodels` können wir die Parameter \\(beta_0, beta_1, beta_2\\) schätzen und Hypothesentests durchführen. Ein positiver Koeffizient bedeutet, dass der Prädiktor die Wahrscheinlichkeit für hohe Sicherheit erhöht; ein negativer verringert sie.\n"
   ],
   "id": "255e47a60d7f61f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Logistische Regression schätzen\n",
    "X = model_df[[\"Log_Homicides\", \"SocialSupport\"]]\n",
    "X = sm.add_constant(X)\n",
    "y = model_df[\"HighSafety\"]\n",
    "\n",
    "logit_model = sm.Logit(y, X).fit(disp=False)\n",
    "logit_model.summary()\n"
   ],
   "id": "33623b8f644fb497"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Odds Ratios und Konfidenzintervalle berechnen\n",
    "params = logit_model.params\n",
    "conf = logit_model.conf_int()\n",
    "\n",
    "odds_ratios = np.exp(params)\n",
    "ci_lower = np.exp(conf[0])\n",
    "ci_upper = np.exp(conf[1])\n",
    "\n",
    "odds_df = pd.DataFrame({\n",
    "    'Coefficient': params,\n",
    "    'Odds_Ratio': odds_ratios,\n",
    "    'CI_lower': ci_lower,\n",
    "    'CI_upper': ci_upper\n",
    "})\n",
    "odds_df\n"
   ],
   "id": "34be9ebb4adfc45f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Modellbewertung\n",
    "model_df['Pred_Prob'] = logit_model.predict(X)\n",
    "model_df['Pred_Class'] = (model_df['Pred_Prob'] >= 0.5).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y, model_df['Pred_Class'])\n",
    "accuracy = accuracy_score(y, model_df['Pred_Class'])\n",
    "auc = roc_auc_score(y, model_df['Pred_Prob'])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y, model_df['Pred_Prob'])\n",
    "\n",
    "{'Confusion_Matrix': cm.tolist(), 'Accuracy': accuracy, 'AUC': auc}\n"
   ],
   "id": "9cf416258a843e70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ROC-Kurve darstellen\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, label=f'ROC-Kurve (AUC = {auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-Kurve der logistischen Regression')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "99f387cbc1c75498"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Interpretation der Ergebnisse\n",
    "\n",
    "- **Koeffizienten:** Die Schätzung `params` aus der logistischen Regression gibt an, wie stark sich eine Einheit Veränderung im Prädiktor auf die Log‑Odds von `HighSafety` auswirkt. Die umgerechneten **Odds Ratios** (> 1 bedeutet Erhöhung der Wahrscheinlichkeit, < 1 Verringerung) erleichtern die Interpretation.\n",
    "\n",
    "  - Ein negativer Koeffizient bei **Log_Homicides** (bzw. ein Odds Ratio < 1) bedeutet, dass höhere Mordraten mit einer geringeren Wahrscheinlichkeit verbunden sind, dass Menschen sich sicher fühlen.\n",
    "  - Ein positiver Koeffizient bei **SocialSupport** (Odds Ratio > 1) zeigt, dass stärkere soziale Unterstützung die Wahrscheinlichkeit erhöht, sich sicher zu fühlen.\n",
    "\n",
    "- **Güte des Modells:** Die Klassifikationsgenauigkeit und die Fläche unter der ROC‑Kurve (AUC) sind Indikatoren für die Vorhersagequalität. In diesem simulierten Beispiel zeigen sie, dass die beiden Prädiktoren gemeinsam eine ordentliche, aber nicht perfekte Trennschärfe besitzen.\n",
    "\n",
    "- **Limitationen:** Da es sich hier um simulierte Daten handelt, sind die konkreten numerischen Ergebnisse nur beispielhaft. Mit dem echten `oecd_snapshot_latest`‑Datensatz sollte die Analyse identisch aufgebaut sein: Der Datensatz müsste in ein breites Format transformiert werden, `Feeling safe at night` dient als Zielgröße, die Schwelle zum Binärwert wird über den Median definiert, und `Homicides` (log‑transformiert) sowie `Social support` fungieren als Prädiktoren.\n",
    "\n",
    "Dieses Notebook veranschaulicht damit die Anwendung der logistischen Regression im Rahmen des Projekts und ergänzt die lineare Regression aus Vorlesung 10 um ein weiteres wichtiges Regressionsverfahren aus Vorlesung 11.\n"
   ],
   "id": "7aadf7b80fc0894a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
