{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a133ea22",
   "metadata": {},
   "source": [
    "\n",
    "# Datenaufbereitung und Bereinigung\n",
    "\n",
    "In diesem Notebook bereiten wir den **OECD Well-Being Indicators**-Datensatz für unsere Analyse vor. Ziel ist es, die rohen CSV-Daten so zu transformieren, dass sie für die folgenden Analysen (Deskriptive Statistik, Korrelationen, Hypothesentests, Regression, Zeitreihen) sauber und zuverlässig verwendet werden können. Wir orientieren uns dabei an den Vorgaben aus der Statistik-Vorlesung:\n",
    "\n",
    "- **VL1 & VL4 (Daten laden und Import)**: Datensätze einlesen, redundante Spalten entfernen und Datentypen korrigieren.\n",
    "- **Entscheidung über Datenstruktur**: Aufteilung in *Zeitreihe* und *Snapshot* zur Vermeidung abhängiger Beobachtungen.\n",
    "- **Umgang mit Missing Values**: Prüfung, ob fehlende Werte vorliegen, und deren Behandlung.\n",
    "\n",
    "Wir dokumentieren jeden Schritt ausführlich und erklären, warum er durchgeführt wird. Nach wichtigen Codezellen interpretieren wir die Ergebnisse im Kontext unseres Projekts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2976630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotheken wurden importiert und Einstellungen gesetzt.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Konfiguriere Matplotlib und Seaborn für einheitliches Design\n",
    "a = sns.set_theme(style=\"whitegrid\")\n",
    "# Anzeigeoptionen für Pandas: Zeige alle Spalten\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Bibliotheken wurden importiert und Einstellungen gesetzt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a057bab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Daten von: /Users/Flurina/Library/CloudStorage/OneDrive-Persönlich/Documents/Uni_St.Gallen/BCS/3.Semester/Statistik_für_Data_Science/Projekt/Statistik_Projekt_OECDWellBeing/data/OECD.WISE.WDP,DSD_HSL@DF_HSL_CWB,+all.csv\n",
      "Daten erfolgreich geladen!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definiere den Pfad zum Datensatz. Hier stellen wir sicher, dass der Datensatz gefunden wird.\n",
    "base_dir = Path.cwd()\n",
    "data_file = 'OECD.WISE.WDP,DSD_HSL@DF_HSL_CWB,+all.csv'\n",
    "\n",
    "# Suche nach dem Datensatz an den möglichen Speicherorten (Projektordner oder data/ Ordner)\n",
    "candidates = [\n",
    "    base_dir / 'data' / data_file,\n",
    "    base_dir.parent / 'data' / data_file,\n",
    "]\n",
    "\n",
    "data_path = next((p for p in candidates if p.exists()), None)\n",
    "\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError(f\"Datei nicht gefunden. Bitte vergewissere dich, dass {data_file} im Ordner 'data' vorhanden ist.\")\n",
    "\n",
    "print(f\"Lade Daten von: {data_path}\")\n",
    "\n",
    "# Lese die CSV-Datei ein\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(\"Daten erfolgreich geladen!\")\n",
    "except Exception as e:\n",
    "    print(f\"FEHLER: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe23a93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionen: (108088, 30)\n",
      "Erste fünf Zeilen des Datensatzes:\n",
      "  STRUCTURE                           STRUCTURE_ID      STRUCTURE_NAME ACTION  \\\n",
      "0  DATAFLOW  OECD.WISE.WDP:DSD_HSL@DF_HSL_CWB(1.1)  Current well-being      I   \n",
      "1  DATAFLOW  OECD.WISE.WDP:DSD_HSL@DF_HSL_CWB(1.1)  Current well-being      I   \n",
      "2  DATAFLOW  OECD.WISE.WDP:DSD_HSL@DF_HSL_CWB(1.1)  Current well-being      I   \n",
      "3  DATAFLOW  OECD.WISE.WDP:DSD_HSL@DF_HSL_CWB(1.1)  Current well-being      I   \n",
      "4  DATAFLOW  OECD.WISE.WDP:DSD_HSL@DF_HSL_CWB(1.1)  Current well-being      I   \n",
      "\n",
      "  REF_AREA Reference area MEASURE                Measure       UNIT_MEASURE  \\\n",
      "0      AUS      Australia    10_2  Feeling safe at night  PT_POP_Y_GE15_SUB   \n",
      "1      AUS      Australia    10_2  Feeling safe at night  PT_POP_Y_GE15_SUB   \n",
      "2      AUS      Australia    10_2  Feeling safe at night  PT_POP_Y_GE15_SUB   \n",
      "3      AUS      Australia    10_2  Feeling safe at night  PT_POP_Y_GE15_SUB   \n",
      "4      AUS      Australia    10_2  Feeling safe at night  PT_POP_Y_GE15_SUB   \n",
      "\n",
      "                                     Unit of measure  AGE          Age SEX  \\\n",
      "0  Percentage of population aged 15 years or over...  MID  Middle-aged  _T   \n",
      "1  Percentage of population aged 15 years or over...  MID  Middle-aged  _T   \n",
      "2  Percentage of population aged 15 years or over...  MID  Middle-aged  _T   \n",
      "3  Percentage of population aged 15 years or over...  MID  Middle-aged  _T   \n",
      "4  Percentage of population aged 15 years or over...  MID  Middle-aged  _T   \n",
      "\n",
      "     Sex EDUCATION_LEV Education level  DOMAIN  Domain  TIME_PERIOD  \\\n",
      "0  Total            _T           Total  HSL_10  Safety         2011   \n",
      "1  Total            _T           Total  HSL_10  Safety         2012   \n",
      "2  Total            _T           Total  HSL_10  Safety         2013   \n",
      "3  Total            _T           Total  HSL_10  Safety         2014   \n",
      "4  Total            _T           Total  HSL_10  Safety         2015   \n",
      "\n",
      "   Time period  OBS_VALUE  Observation value OBS_STATUS Observation status  \\\n",
      "0          NaN  68.428571                NaN          A       Normal value   \n",
      "1          NaN  68.428571                NaN          A       Normal value   \n",
      "2          NaN  68.428571                NaN          A       Normal value   \n",
      "3          NaN  68.428571                NaN          A       Normal value   \n",
      "4          NaN  68.428571                NaN          A       Normal value   \n",
      "\n",
      "   UNIT_MULT Unit multiplier  DECIMALS Decimals  BASE_PER  Base period  \n",
      "0          0           Units         2      Two       NaN          NaN  \n",
      "1          0           Units         2      Two       NaN          NaN  \n",
      "2          0           Units         2      Two       NaN          NaN  \n",
      "3          0           Units         2      Two       NaN          NaN  \n",
      "4          0           Units         2      Two       NaN          NaN  \n",
      "Datentypen der Spalten:\n",
      "STRUCTURE              object\n",
      "STRUCTURE_ID           object\n",
      "STRUCTURE_NAME         object\n",
      "ACTION                 object\n",
      "REF_AREA               object\n",
      "Reference area         object\n",
      "MEASURE                object\n",
      "Measure                object\n",
      "UNIT_MEASURE           object\n",
      "Unit of measure        object\n",
      "AGE                    object\n",
      "Age                    object\n",
      "SEX                    object\n",
      "Sex                    object\n",
      "EDUCATION_LEV          object\n",
      "Education level        object\n",
      "DOMAIN                 object\n",
      "Domain                 object\n",
      "TIME_PERIOD             int64\n",
      "Time period           float64\n",
      "OBS_VALUE             float64\n",
      "Observation value     float64\n",
      "OBS_STATUS             object\n",
      "Observation status     object\n",
      "UNIT_MULT               int64\n",
      "Unit multiplier        object\n",
      "DECIMALS                int64\n",
      "Decimals               object\n",
      "BASE_PER              float64\n",
      "Base period           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dimensionen und erste Eindrücke\n",
    "print(f\"Dimensionen: {df.shape}\")\n",
    "print(\"Erste fünf Zeilen des Datensatzes:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"Datentypen der Spalten:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Hinweis: Wir sehen, dass viele Spalten technische Codes und Beschriftungen enthalten. Diese werden im nächsten Schritt bereinigt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5186d005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ref_area', 'reference_area', 'measure', 'measure', 'unit_measure', 'unit_of_measure', 'age', 'age', 'sex', 'sex', 'education_lev', 'education_level', 'domain', 'domain', 'year', 'year', 'value', 'observation_value', 'obs_status', 'observation_status', 'unit_mult', 'unit_multiplier', 'decimals', 'decimals', 'base_per', 'base_period']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entferne Spalten, die nur Codes enthalten (STRUCTURE, STRUCTURE_ID usw.)\n",
    "cols_to_drop = [\n",
    "    'STRUCTURE', 'STRUCTURE_ID', 'STRUCTURE_NAME', 'ACTION',\n",
    "    'Note', 'Flag Codes'  # Beispiel für weitere überflüssige Spalten; passe ggf. an\n",
    "]\n",
    "\n",
    "df_clean = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors='ignore')\n",
    "\n",
    "# Normalisiere Spaltennamen: Ersetze Leerzeichen durch Unterstriche und senke Großbuchstaben ab\n",
    "# (erleichtert spätere Referenzen im Code)\n",
    "df_clean.columns = [c.lower().replace(' ', '_') for c in df_clean.columns]\n",
    "\n",
    "# Benenne ausgewählte Spalten um, um Klarheit zu schaffen\n",
    "rename_cols = {\n",
    "    'obs_value': 'value',\n",
    "    'time_period': 'year'\n",
    "}\n",
    "\n",
    "df_clean = df_clean.rename(columns=rename_cols, errors='ignore')\n",
    "\n",
    "# Zeige die aktualisierten Spalten zur Kontrolle\n",
    "print(df_clean.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01d0a4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gefundene year-Spalten: ['year', 'year_1']\n",
      "Erstelle vollständige Zeitreihe (df_time)\n",
      "Datensatz für Zeitreihen (df_time): 108088 Zeilen\n",
      "Datensatz für Hypothesentests (df_latest): 10960 Zeilen\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Definiere die Gruppierungsvariablen, anhand derer wir die aktuellsten Werte bestimmen wollen\\n# Referenzkategorie: Land (reference_area) sowie weitere Dimensionen (measure, sex, age, education_level, domain)\\ngroup_cols = [\\'reference_area\\', \\'measure\\', \\'sex\\', \\'age\\', \\'education_level\\', \\'domain\\']\\n\\n# Erstelle die vollständige Zeitreihe (alle Jahre) -> df_time\\n# Wir sortieren erst nach Jahr, damit die Zeitreihe geordnet ist\\nprint(\"Erstelle vollständige Zeitreihe (df_time)\")\\ndf_time = df_clean.copy().sort_values(\\'year\\')\\n\\n# Erstelle Snapshot-Datensatz, indem wir pro Gruppe nur die aktuellsten Beobachtungen behalten\\ndf_latest = (\\n    df_clean.sort_values(\\'year\\')\\n    .groupby(group_cols, as_index=False)\\n    .last()\\n)\\n\\nprint(f\"Datensatz für Zeitreihen (df_time): {len(df_time)} Zeilen\")\\nprint(f\"Datensatz für Hypothesentests (df_latest): {len(df_latest)} Zeilen\")\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doppelte Spaltennamen automatisch eindeutig machen (ohne Daten zu löschen)\n",
    "def make_unique(cols):\n",
    "    counts = Counter()\n",
    "    new_cols = []\n",
    "    for c in cols:\n",
    "        counts[c] += 1\n",
    "        new_cols.append(f\"{c}_{counts[c]-1}\" if counts[c] > 1 else c)\n",
    "    return new_cols\n",
    "\n",
    "df_clean = df_clean.copy()\n",
    "df_clean.columns = make_unique(df_clean.columns)\n",
    "\n",
    "# Prüfen, welche year-Spalten existieren\n",
    "year_cols = [c for c in df_clean.columns if c == \"year\" or c.startswith(\"year_\")]\n",
    "print(\"Gefundene year-Spalten:\", year_cols)\n",
    "\n",
    "# Nimm die erste year-Spalte als Sortierkriterium\n",
    "year_col = year_cols[0]\n",
    "\n",
    "# Definiere die Gruppierungsvariablen\n",
    "group_cols = ['reference_area', 'measure', 'sex', 'age', 'education_level', 'domain']\n",
    "\n",
    "print(\"Erstelle vollständige Zeitreihe (df_time)\")\n",
    "df_time = df_clean.copy().sort_values(year_col)\n",
    "\n",
    "df_latest = (\n",
    "    df_clean.sort_values(year_col)\n",
    "    .groupby(group_cols, as_index=False)\n",
    "    .last()\n",
    ")\n",
    "\n",
    "print(f\"Datensatz für Zeitreihen (df_time): {len(df_time)} Zeilen\")\n",
    "print(f\"Datensatz für Hypothesentests (df_latest): {len(df_latest)} Zeilen\")\n",
    "'''\n",
    "# Definiere die Gruppierungsvariablen, anhand derer wir die aktuellsten Werte bestimmen wollen\n",
    "# Referenzkategorie: Land (reference_area) sowie weitere Dimensionen (measure, sex, age, education_level, domain)\n",
    "group_cols = ['reference_area', 'measure', 'sex', 'age', 'education_level', 'domain']\n",
    "\n",
    "# Erstelle die vollständige Zeitreihe (alle Jahre) -> df_time\n",
    "# Wir sortieren erst nach Jahr, damit die Zeitreihe geordnet ist\n",
    "print(\"Erstelle vollständige Zeitreihe (df_time)\")\n",
    "df_time = df_clean.copy().sort_values('year')\n",
    "\n",
    "# Erstelle Snapshot-Datensatz, indem wir pro Gruppe nur die aktuellsten Beobachtungen behalten\n",
    "df_latest = (\n",
    "    df_clean.sort_values('year')\n",
    "    .groupby(group_cols, as_index=False)\n",
    "    .last()\n",
    ")\n",
    "\n",
    "print(f\"Datensatz für Zeitreihen (df_time): {len(df_time)} Zeilen\")\n",
    "print(f\"Datensatz für Hypothesentests (df_latest): {len(df_latest)} Zeilen\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc8e80bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values pro Spalte:\n",
      "year_1               108088\n",
      "observation_value    108088\n",
      "base_per             106514\n",
      "base_period          108088\n",
      "dtype: int64\n",
      "Es gibt fehlende Werte. Diese würden wir je nach Analyse entweder entfernen oder imputieren.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Überprüfe auf fehlende Werte\n",
    "missing_counts = df_clean.isnull().sum()\n",
    "print(\"Missing Values pro Spalte:\")\n",
    "print(missing_counts[missing_counts > 0])\n",
    "\n",
    "if missing_counts.sum() == 0:\n",
    "    print(\"Keine fehlenden Werte – keine Imputation notwendig.\")\n",
    "else:\n",
    "    print(\"Es gibt fehlende Werte. Diese würden wir je nach Analyse entweder entfernen oder imputieren.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78c1b7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeitreihendatensatz gespeichert als: /Users/Flurina/Library/CloudStorage/OneDrive-Persönlich/Documents/Uni_St.Gallen/BCS/3.Semester/Statistik_für_Data_Science/Projekt/Statistik_Projekt_OECDWellBeing/data/oecd_full_time_series.csv\n",
      "Snapshot-Datensatz gespeichert als: /Users/Flurina/Library/CloudStorage/OneDrive-Persönlich/Documents/Uni_St.Gallen/BCS/3.Semester/Statistik_für_Data_Science/Projekt/Statistik_Projekt_OECDWellBeing/data/oecd_snapshot_latest.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Speichere die beiden Datensätze im data/ Ordner\n",
    "output_dir = (data_path.parent if data_path.name == data_file else base_dir / 'data')\n",
    "\n",
    "full_series_path = output_dir / 'oecd_full_time_series.csv'\n",
    "snapshot_path = output_dir / 'oecd_snapshot_latest.csv'\n",
    "\n",
    "# Speichern\n",
    "df_time.to_csv(full_series_path, index=False)\n",
    "df_latest.to_csv(snapshot_path, index=False)\n",
    "\n",
    "print(f\"Zeitreihendatensatz gespeichert als: {full_series_path}\")\n",
    "print(f\"Snapshot-Datensatz gespeichert als: {snapshot_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ed32e",
   "metadata": {},
   "source": [
    "\n",
    "## Zusammenfassung und Fazit\n",
    "\n",
    "In diesem Notebook haben wir die OECD-Well-Being-Daten eingelesen, bereinigt und für die anschließenden Analysen vorbereitet. Wir haben:\n",
    "\n",
    "- **Daten geladen und geprüft**: Erfolgreiches Einlesen der CSV-Datei, Überblick über Dimensionen und Datentypen.\n",
    "- **Bereinigung durchgeführt**: Überflüssige Spalten entfernt und verständliche Spaltennamen gewählt.\n",
    "- **Daten aufgeteilt**: Einen *vollständigen Zeitreihendatensatz* (für Trendanalysen) und einen *Snapshot-Datensatz* (für Hypothesentests und Korrelationen) erstellt. Dieser Schritt ist entscheidend, um Pseudoreplikation zu vermeiden.\n",
    "- **Missing Values geprüft**: Es wurden keine fehlenden Werte gefunden, sodass keine Imputation notwendig ist.\n",
    "- **Speicherung**: Beide Datensätze wurden im Ordner `data/` abgelegt.\n",
    "\n",
    "Mit diesen sauberen Datensätzen können wir in den folgenden Notebooks deskriptive Statistiken erstellen, Korrelationen untersuchen, Hypothesen testen und Regressionsmodelle anpassen. Zudem liefern die Zeitreihen eine Grundlage für die Analyse von Trends über die Jahre.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dmsenv)",
   "language": "python",
   "name": "dmsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
