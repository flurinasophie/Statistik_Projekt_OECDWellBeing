{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Regressionsanalyse & Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Aus Notebook 03 wissen wir, dass sich für *Homicides* und *Feeling safe at night* **kein signifikanter monotoner Zusammenhang** (Spearman / Kendall) nachweisen ließ. In Notebook 04 haben wir aber gesehen, dass Länder mit hoher Mordrate im Mittel ein **niedrigeres Sicherheitsgefühl** berichten als Länder mit niedriger Mordrate.\n",
    "\n",
    "In diesem Notebook knüpfen wir daran an und betrachten denselben Zusammenhang im Rahmen von **Regressionsmodellen**. Ziel ist es, die Stärke und Richtung des Effekts von *Homicides* (und später *Social support*) auf das Sicherheitsgefühl zu quantifizieren und zu prüfen, ob diese Effekte auch dann bestehen bleiben, wenn mehrere Einflussfaktoren gleichzeitig im Modell sind – genau so, wie es in der Vorlesung zu Regression und Modellierung (Kapitel „lineare Modelle“, OLS, Gauss-Markov) behandelt wurde.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "In den vorherigen Notebooks haben wir\n",
    "\n",
    "- die Verteilung und Ausreißer unserer Variablen untersucht (Notebook 02),\n",
    "- Zusammenhänge über Korrelationen analysiert (Notebook 03),\n",
    "- und Gruppenvergleiche vorgenommen (Notebook 04).\n",
    "\n",
    "Hier gehen wir einen Schritt weiter und **modellieren** den Einfluss ausgewählter erklärender Variablen auf unsere Zielvariable:\n",
    "\n",
    "> **Zielvariable:** *Feeling safe at night* (Sicherheitsgefühl)\n",
    "\n",
    "Wir konzentrieren uns auf die Frage:\n",
    "\n",
    "> *Wie stark erklärt die objektive Mordrate (Homicides) und die soziale Unterstützung (Social support), wie sicher sich Menschen nachts fühlen?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from pathlib import Path\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 1. Daten laden & Vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Für die Regressionsanalyse in diesem Notebook brauchen wir **pro Land genau eine Beobachtung**, um Pseudoreplikation zu vermeiden.  \n",
    "Deshalb verwenden wir **`oecd_snapshot_latest.csv`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.cwd()\n",
    "data_file = 'oecd_snapshot_latest.csv'\n",
    "candidates = [\n",
    "    base_dir / 'data' / data_file,\n",
    "    base_dir.parent / 'data' / data_file,\n",
    "]\n",
    "data_path = next((p for p in candidates if p.exists()), None)\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError(f\"Datei nicht gefunden. Versucht wurden: {candidates}\")\n",
    "print(f\"Lade Daten von: {data_path}\")\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_interest = ['Feeling safe at night', 'Homicides', 'Social support', 'Life satisfaction']\n",
    "df_filtered = df[df['measure'].isin(cols_of_interest)].copy()\n",
    "df_filtered['value'] = pd.to_numeric(df_filtered['value'], errors='coerce')\n",
    "\n",
    "df_pivot = df_filtered.pivot_table(\n",
    "    index='reference_area',\n",
    "    columns='measure',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "df_pivot = df_pivot.dropna()\n",
    "\n",
    "df_pivot.columns = ['FeelingSafe', 'Homicides', 'LifeSat', 'SocialSupport']\n",
    "\n",
    "print(f\"Anzahl der Länder im Modell: {len(df_pivot)}\")\n",
    "df_pivot.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Regression vs. Korrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Bevor wir rechnen, grenzen wir die Methode ab:\n",
    "\n",
    "* Korrelation (NB 03): Misst die Stärke und Richtung eines linearen Zusammenhangs zwischen zwei Variablen (z. B. r=−0.7 zwischen Mordrate und Sicherheit). Es gibt keine Unterscheidung in Ursache und Wirkung.\n",
    "\n",
    "* Regression (NB 05): Modelliert eine gerichtete Beziehung. Wir definieren eine abhängige Variable Y (Sicherheit) und erklären sie durch unabhängige Variablen X (Mordrate).\n",
    "    * Ziel: Vorhersage und Quantifizierung des Effekts (\"Wenn Mordrate um 1 steigt, sinkt Sicherheit um β\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 2. Einfache Lineare Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Aus Notebook 03 wissen wir, dass wir **keinen statistisch signifikanten monotonen Zusammenhang** zwischen Mordrate (Homicides) und dem Sicherheitsgefühl nachweisen konnten. Die Spearman-Korrelation lag nahe bei null und die Hypothese eines monotonen Zusammenhangs wurde beibehalten.\n",
    "\n",
    "Theoretisch und visuell (Scatterplot) erwarten wir aber trotzdem, dass höhere Mordraten eher mit einem geringeren Sicherheitsgefühl einhergehen könnten.\n",
    "Mit der Regressionsanalyse prüfen wir nun, ob sich in einem gerichteten linearen Modell (einfache OLS-Regression) ein systematischer Effekt der Mordrate auf das Sicherheitsgefühl zeigt.\n",
    "\n",
    "Die einfache lineare Regression nutzen wir nun, um diesen möglichen Effekt gerichteter zu modellieren und zu quantifizieren: Wie stark ändert sich das erwartete Sicherheitsgefühl, wenn die Mordrate um eine Einheit steigt?\n",
    "\n",
    "Wir starten mit dem einfachsten Modell -> Ordinary Least Squares (OLS): Wir schätzen die Gerade, die die Summe der quadrierten Abweichungen (Residuen) zwischen den echten Datenpunkten und der Geraden minimiert.\n",
    "\n",
    "-> $FeelingSafe = \\beta_0 + \\beta_1 \\cdot Homicides + \\varepsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Wir haben gesehen, dass Homicides extrem rechtsschief ist und starke Ausreißer hat. Eine lineare Regression auf rohen Daten wäre hier problematisch, da diese Ausreißer die Regressionsgerade unverhältnismäßig stark beeinflussen (\"Hebelwirkung\").\n",
    "\n",
    "=> Lösung: Wir logarithmieren die Mordrate (Log_Homicides). Dies linearisiert oft Zusammenhänge, die exponentiell abnehmen (der Unterschied zwischen 1 und 2 Morden wiegt schwerer als zwischen 20 und 21)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell definieren und fitten\n",
    "model_simple = ols('FeelingSafe ~ Homicides', data=df_pivot).fit()\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(model_simple.summary())\n",
    "\n",
    "# Visualisierung der Regressionsgeraden\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='Homicides', y='FeelingSafe', data=df_pivot, \n",
    "            scatter_kws={'alpha':0.6}, line_kws={'color':'red'})\n",
    "plt.title('Einfache Lineare Regression: Einfluss der Mordrate auf das Sicherheitsgefühl')\n",
    "plt.xlabel('Mordrate (pro 100k Einwohner)')\n",
    "plt.ylabel('Sicherheitsgefühl (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Interpretation des OLS-Outputs (einfaches Modell mit `Homicides`)\n",
    "\n",
    "Der OLS-Output für das Modell `FeelingSafe ~ Homicides`\n",
    "\n",
    "- **Intercept $\\beta_0 \\approx 77.14$**  \n",
    "  - Für ein Land mit **Mordrate = 0** schätzt das Modell ein Sicherheitsgefühl von etwa **77 %**. Das ist der erwartete Basiswert ohne Morde\n",
    "  - In der Realität hat kein Land exakt 0 Morde, aber der Intercept ist als **theoretischer Referenzpunkt** nützlich\n",
    "\n",
    "- **Steigung $\\beta_1 \\approx -1.10$** (p < 0.001):  \n",
    "  - Bei einer Erhöhung der Mordrate um **1 Mord pro 100 000 Einwohner** sinkt das Sicherheitsgefühl im Mittel um etwa **1.1 Prozentpunkte**  \n",
    "  - Das Vorzeichen ist negativ (wie aus der Theorie und den vorherigen Plots erwartbar)\n",
    "\n",
    "- **Signifikanztest (t-Statistik, p-Wert):**  \n",
    "  - Die t-Statistik für `Homicides` ist groß im Betrag ($\\approx$ −5.04) und der p-Wert ist deutlich kleiner als 0.05\n",
    "\n",
    "    -> Wir verwerfen die Nullhypothese $\\beta_1 = 0$. Die Mordrate hat einen **signifikanten linearen Zusammenhang** mit dem Sicherheitsgefühl\n",
    "\n",
    "- **Modellgüte ($R^2 \\approx 0.414$, Adj. $R^2 \\approx 0.398$):**  \n",
    "  - Rund **41 % der Varianz** des Sicherheitsgefühls zwischen den Ländern werden durch die Mordrate allein erklärt.\n",
    "  - Für ein Modell mit nur einem Prädiktor ist das ein **relativ hoher Erklärungsanteil**\n",
    "\n",
    "Die ersten Ergebnisse sind also konsistent mit unseren Hypothesen aus den Notebooks 02–04:  \n",
    "In Ländern mit objektiv höherer Gewaltbelastung fühlen sich die Menschen im Durchschnitt **weniger sicher**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Hinweis: Die geschätzten Zusammenhänge sind als **assoziativ** zu interpretieren.\n",
    "Auch multiple Regressions- und Fixed-Effects-Modelle erlauben ohne zusätzliche\n",
    "Identifikationsannahmen **keine kausalen Schlussfolgerungen**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 3. Analyse der Gütemaße"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gütemaße extrahieren\n",
    "r_squared = model_simple.rsquared\n",
    "ess = model_simple.ess\n",
    "rss = model_simple.ssr  # Residual Sum of Squares\n",
    "n = model_simple.nobs\n",
    "p = model_simple.df_model\n",
    "rse = np.sqrt(rss / (n - p - 1)) # RSE Formel: sqrt(RSS / degrees of freedom)\n",
    "\n",
    "print(\"--- Gütemaße der Regression ---\")\n",
    "print(f\"R-Squared (R²): {r_squared:.4f} (Das Modell erklärt {r_squared*100:.1f}% der Varianz im Sicherheitsgefühl)\")\n",
    "print(f\"Explained Sum of Squares (ESS): {ess:.2f}\")\n",
    "print(f\"Residual Sum of Squares (RSS):  {rss:.2f}\")\n",
    "print(f\"Residual Standard Error (RSE):  {rse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 3. Gütemaße des einfachen Modells (R², ESS, RSS, RSE)\n",
    "- **$R^2 \\approx$ 0.346** – Das Modell erklärt etwa **34.6 % der Varianz** im Sicherheitsgefühl\n",
    "- **ESS $\\approx$ 1415.9** – durch das Modell erklärte Streuung\n",
    "- **RSS $\\approx$ 2676.4** – verbleibende Streuung (Residuen)\n",
    "- **RSE $\\approx$ 8.62** – die Modellvorhersagen weichen im Mittel um rund **8.6 Prozentpunkte** vom tatsächlichen Sicherheitsgefühl ab\n",
    "\n",
    "- Die Mordrate erklärt einen substanziellen, aber nicht vollständigen Teil der Unterschiede zwischen Ländern. Andere Faktoren spielen offensichtlich ebenfalls eine Rolle.\n",
    "- Ein RSE von ~8–9 Prozentpunkten ist im Kontext eines Mittelwerts von ~75 % Sicherheitsgefühl nicht riesig, aber auch nicht vernachlässigbar -> somit ist das Modell brauchbar, aber noch ausbaufähig."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 4. Erweiterung: Multiple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Wie oben festgestellt, hängt Sicherheit nicht nur von Morden ab. Aus Notebook 03 wissen wir, dass auch soziale Unterstützung (SocialSupport) korreliert. Wir fügen diese Variable hinzu, um zu sehen, ob sie zusätzlich zur Mordrate einen Einfluss hat.\n",
    "\n",
    "Modellgleichung: $FeelingSafe = \\beta_0 + \\beta_1 \\cdot \\log(Homicides) + \\beta_2 \\cdot SocialSupport + \\varepsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Die ausgewählten erklärenden Variablen kombinieren einen **objektiven\n",
    "Sicherheitsindikator** (Logarithmus der Mordrate) mit einem **subjektiven sozialen\n",
    "Faktor** (soziale Unterstützung) und erlauben damit eine inhaltlich plausible\n",
    "Modellierung des Sicherheitsgefühls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Regression: Log(Mordrate) + Soziale Unterstützung\n",
    "if 'Log_Homicides' not in df_pivot.columns:\n",
    "    df_pivot['Log_Homicides'] = np.log(df_pivot['Homicides'])\n",
    "\n",
    "# Sicherstellen, dass keine Inf/NaN in den Prädiktoren sind\n",
    "df_multi = df_pivot[['FeelingSafe', 'Log_Homicides', 'SocialSupport']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "model_multi = ols('FeelingSafe ~ Log_Homicides + SocialSupport', data=df_multi).fit()\n",
    "\n",
    "print(model_multi.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Zerlegung der Varianz: TSS = ESS + RSS (VL10)\n",
    "\n",
    "In der linearen Regression kann die Gesamtstreuung der Zielvariable in erklärte und nicht erklärte Anteile zerlegt werden:\n",
    "\n",
    "- **TSS (Total Sum of Squares)**: gesamte Streuung von `FeelingSafe` um den Mittelwert  \n",
    "- **ESS (Explained Sum of Squares)**: durch das Regressionsmodell erklärte Streuung  \n",
    "- **RSS (Residual Sum of Squares)**: nicht erklärte Streuung (Residuen)\n",
    "\n",
    "Theoretisch gilt:\n",
    "\\[\n",
    "\\text{TSS} = \\text{ESS} + \\text{RSS}\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zielvariable und Vorhersagen\n",
    "y = model_multi.model.endog\n",
    "y_hat = model_multi.fittedvalues\n",
    "\n",
    "# Mittelwert der Zielvariable\n",
    "y_mean = y.mean()\n",
    "\n",
    "# Total Sum of Squares (TSS)\n",
    "TSS = ((y - y_mean) ** 2).sum()\n",
    "\n",
    "# Explained Sum of Squares (ESS)\n",
    "ESS = ((y_hat - y_mean) ** 2).sum()\n",
    "\n",
    "# Residual Sum of Squares (RSS)\n",
    "RSS = ((y - y_hat) ** 2).sum()\n",
    "\n",
    "TSS, ESS, RSS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfung der Zerlegung\n",
    "print(f\"TSS       = {TSS:.4f}\")\n",
    "print(f\"ESS + RSS = {(ESS + RSS):.4f}\")\n",
    "print(f\"Differenz = {(TSS - (ESS + RSS)):.10f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "Die numerische Überprüfung bestätigt die theoretische Zerlegung:\n",
    "\\[\n",
    "\\text{TSS} = \\text{ESS} + \\text{RSS}\n",
    "\\]\n",
    "\n",
    "- Der Quotient **ESS / TSS** entspricht dem **Bestimmtheitsmaß \\(R^2\\)**.\n",
    "- **RSS / TSS** beschreibt den nicht erklärten Varianzanteil.\n",
    "- Diese Zerlegung ist zentral für die Bewertung der Modellgüte in der linearen Regression (VL10).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Auswertung der Multiplen Regression mit `Log_Homicides` und `SocialSupport`\n",
    "\n",
    "Der OLS-Output für dieses Modell zeigt:   \n",
    "\n",
    "- **$R^2 \\approx 0.491$, Adj. $R^2 \\approx 0.462$**  \n",
    "  - Das Modell erklärt nun knapp **49 % der Varianz** im Sicherheitsgefühl – deutlich mehr als die einfache Regression.\n",
    "- **F-Statistik p < 0.001**  \n",
    "  - Das Gesamtmodell ist hoch signifikant; mindestens ein Prädiktor trägt substantiell zur Erklärung bei\n",
    "\n",
    "**Koeffizienten (vereinfacht interpretiert):**\n",
    "\n",
    "- $\\beta_1$ für `Log_Homicides` ≈ **−4.79** (p ≈ 0.001)  \n",
    "  - Bei höherer log-Mordrate (also „eine Stufe mehr Gewaltbelastung“) sinkt das Sicherheitsgefühl ceteris paribus um rund **4–5 Prozentpunkte**.\n",
    "- $\\beta_2$ für `SocialSupport` ≈ **+1.05** (p ≈ 0.002)  \n",
    "  - Ein zusätzlicher Prozentpunkt in sozialer Unterstützung geht mit ungefähr **+1 Prozentpunkt** im Sicherheitsgefühl einher – bei konstanter log-Mordrate.\n",
    "\n",
    "Damit bestätigt das Multiple-Modell unsere inhaltliche Hypothese:\n",
    "\n",
    "> **Hohe Mordraten** und **geringe soziale Unterstützung** sind beide mit einem niedrigeren subjektiven Sicherheitsgefühl verbunden – und beide Effekte bleiben bestehen, wenn der jeweils andere kontrolliert wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## 5. Residuenanalyse & Modellannahmen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Ein Regressionsmodell ist statistisch nur valide, wenn die Gauss-Markov-Annahmen erfüllt sind. Wir prüfen diese visuell und rechnerisch anhand der Residuen (Fehlerterme) des multiplen Modells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### 5.1 Residuen-Plots (Linearität & Homoskedastizität)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "* Annahme 1 (Linearität): Der Zusammenhang ist linear.\n",
    "* Annahme 2 (Homoskedastizität): Die Varianz der Fehler ist konstant (kein \"Trichter\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = model_multi.resid\n",
    "fitted_vals = model_multi.fittedvalues\n",
    "\n",
    "# Plot: Residuen vs. Fitted Values\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=fitted_vals, y=residuals, color='blue', alpha=0.6)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Gefittete Werte (Vorhersage)')\n",
    "plt.ylabel('Residuen (Fehler)')\n",
    "plt.title('Residuen vs. Fitted Values (Prüfung auf Linearität & Homoskedastizität)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Im Plot „Residuen vs. Fitted“ für das Multiple-Modell sehen wir:\n",
    "\n",
    "- Die Residuen sind über den Bereich der vorhergesagten Werte ungefähr **zufällig verteilt**.\n",
    "- Kein klarer **systematischer Trend** (z. B. gekrümmter Verlauf), der auf eine starke **Nichtlinearität** der Beziehung hinweisen würde.\n",
    "- Es gibt einige Punkte mit etwas größeren Residuen, aber keine extremen Muster, bei denen die Varianz mit der Vorhersage stark zunimmt oder abnimmt.\n",
    "\n",
    "**Interpretation:**  \n",
    "Die **Linearitätsannahme** ist für dieses Modell **plausibel erfüllt**; Homoskedastizität ist jedenfalls nicht drastisch verletzt. Kleinere Abweichungen sind bei echten Daten normal, aber es gibt keinen offensichtlichen Grund, das Modell wegen schwerer Missspezifikation zu verwerfen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### 5.2 Normalität der Residuen (QQ-Plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "* Annahme 3: Die Fehlerterme sind normalverteilt. Dies ist wichtig für die Gültigkeit der p-Werte und Konfidenzintervalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Histogramm der Residuen\n",
    "sns.histplot(residuals, kde=True, ax=axes[0], color='green')\n",
    "axes[0].set_title('Histogramm der Residuen')\n",
    "\n",
    "# QQ-Plot\n",
    "sm.qqplot(residuals, line='45', fit=True, ax=axes[1])\n",
    "axes[1].set_title('Q-Q Plot der Residuen')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Formaler Test (Shapiro-Wilk auf Residuen)\n",
    "shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
    "print(f\"Shapiro-Wilk Test auf Normalität der Residuen: p = {shapiro_p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Der **QQ-Plot der Residuen** des Multiple-Modells zeigt:   \n",
    "\n",
    "- Die Punkte liegen überwiegend **nahe an der Diagonalen**, nur in den Extrembereichen gibt es leichte Abweichungen (typisch für reale Datensätze).\n",
    "- Es gibt **keine extremen Ausreißer** in den Residuen.\n",
    "\n",
    "Der **Shapiro-Wilk-Test** liefert:\n",
    "\n",
    "- Teststatistik ≈ 0.97  \n",
    "- p-Wert ≈ **0.86** (>> 0.05) \n",
    "\n",
    "**Interpretation gemäß Vorlesung:**\n",
    "\n",
    "- Nullhypothese: „Die Residuen sind normalverteilt.“\n",
    "- Da p ≫ 0.05, **können wir die Nullhypothese nicht verwerfen**.\n",
    "- → Die Annahme einer **ungefähren Normalverteilung der Residuen** ist für dieses Modell gut vertretbar.\n",
    "\n",
    "In Kombination mit der Durbin-Watson-Statistik (~2.29) spricht nichts für eine starke Autokorrelation (was bei Querschnittsdaten ohnehin weniger problematisch ist). Damit sind die Annahmen für Signifikanztests und Konfidenzintervalle **hinreichend erfüllt**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## 6. Ausreißer & Einflussreiche Punkte (Cook's Distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Nicht jeder Ausreißer ist schlimm. Aber einflussreiche Punkte (hohe Leverage + hohes Residuum) können die Regressionsgerade \"verbiegen\". Wir identifizieren diese mit Cook's Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cook's Distance berechnen\n",
    "influence = model_multi.get_influence()\n",
    "cooks_d = influence.cooks_distance[0]\n",
    "\n",
    "# Visualisierung (Stem-Plot)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.stem(np.arange(len(df_pivot)), cooks_d, markerfmt=\",\")\n",
    "plt.title(\"Cook's Distance: Identifikation einflussreicher Länder\")\n",
    "plt.xlabel('Länder Index')\n",
    "plt.ylabel(\"Cook's Distance\")\n",
    "\n",
    "# Schwellenwert einzeichnen (Daumenregel: 4/n)\n",
    "threshold = 4 / len(df_pivot)\n",
    "plt.axhline(threshold, color='red', linestyle='--', label=f'Threshold (4/n = {threshold:.2f})')\n",
    "plt.legend()\n",
    "\n",
    "# Labels für Punkte über dem Schwellenwert hinzufügen\n",
    "influential_indices = np.where(cooks_d > threshold)[0]\n",
    "for idx in influential_indices:\n",
    "    country_name = df_pivot.index[idx]\n",
    "    plt.text(idx, cooks_d[idx], country_name, fontsize=9, rotation=45)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Länder mit hohem Einfluss auf das Modell (Cook's D > Threshold):\")\n",
    "print(df_pivot.index[influential_indices].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Im Cook’s-Distance-Plot sehen wir:\n",
    "\n",
    "- Einige Länder mit höherer Mordrate liegen über dem Durchschnitt der Distanzen\n",
    "- Allerdings bleibt keine Beobachtung deutlich über der Faustregel (z. B. $4/n$ oder 1), die auf „extrem einflussreiche“ Punkte hindeuten würde\n",
    "\n",
    "**Entscheidung: Wir entfernen keine Länder aus dem Datensatz.**\n",
    "  - Die auffälligen Länder sind aus **substanzieller Sicht relevant** -> hohe Mordrate \n",
    "  - Ihre Cook’s Distance ist erhöht, aber nicht so hoch, dass das Modell offensichtlich durch einzelne Ausreißer „zerstört“ wird  \n",
    "  - Das Modell bleibt interpretierbar und gerade die Extreme sind für die OECD-Wellbeing-Perspektive informativ\n",
    "\n",
    "-> Wir wenden bewusst keine **bewusst keine Outlier-Trimming-Strategie** an, sondern arbeiten mit dem realen Länderspektrum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## 7. Modell-Optimierung: Log-Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "Unsere Analyse in Notebook 02 hat gezeigt, dass Homicides extrem rechtsschief ist und Ausreißer hat. Lineare Regression setzt zwar keine Normalverteilung der Variablen voraus, aber Ausreißer in X haben einen enormen Leverage auf die Regressionsgerade. Eine Log-Transformation der Mordrate kann diesen Einfluss dämpfen und den Zusammenhang linearisieren.\n",
    "\n",
    "Modellgleichung: $FeelingSafe = \\beta_0 + \\beta_1 \\cdot \\log(Homicides) + \\varepsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-Transformation der Mordrate\n",
    "df_pivot['Log_Homicides'] = np.log(df_pivot['Homicides'])\n",
    "\n",
    "# Neues Modell fitten\n",
    "model_log = ols('FeelingSafe ~ Log_Homicides', data=df_pivot).fit()\n",
    "\n",
    "print(model_log.summary())\n",
    "\n",
    "# Visualisierung mit transformierter Variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='Log_Homicides', y='FeelingSafe', data=df_pivot, \n",
    "            scatter_kws={'alpha':0.6}, line_kws={'color':'green'})\n",
    "plt.title('Optimiertes Modell: Sicherheitsgefühl vs. Log(Mordrate)')\n",
    "plt.xlabel('Log(Mordrate)')\n",
    "plt.ylabel('Sicherheitsgefühl (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "- $\\beta_1 \\approx -5.89$, p < 0.001:  \n",
    "  - Eine Zunahme der log-Mordrate (z. B. von sehr niedrigen zu mittleren Werten) führt im Mittel zu einem **stärkeren Rückgang** im Sicherheitsgefühl als im oberen Bereich\n",
    "- R² ≈ **0.33**:  \n",
    "  - Das log-Modell erklärt etwas weniger Varianz als die einfache Regression mit roher Mordrate (R² ≈ 0.41), bietet aber **bessere Voraussetzungen** für Linearität und Residuenverhalten\n",
    "\n",
    "Im Plot „FeelingSafe vs. Log_Homicides“ mit Regressionsgerade sieht man:\n",
    "\n",
    "- Eine **klarere lineare Struktur** über den gesamten Wertebereich\n",
    "- Die Extremwerte sind in der Skala „zusammengedrückt“, wodurch sie den Fit weniger dominieren\n",
    "\n",
    "**=>**\n",
    "\n",
    "- Rein vom R² ist die Version mit roher Mordrate minimal besser\n",
    "- Hinsichtlich **Modellannahmen** und **Interpretierbarkeit** des Effekts über den gesamten Bereich ist die **log-transformierte Variante** sinnvoller, insbesondere als Basis für die Multiple Regression mit SocialSupport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### 7.3 Vergleich der Modellvarianten\n",
    "\n",
    "Zusammenfassend vergleichen wir die zentralen Modellvarianten:\n",
    "\n",
    "1. **Einfaches Modell (roh):** `FeelingSafe ~ Homicides`  \n",
    "   - R² ≈ 0.41  \n",
    "   - Klarer negativer Effekt, aber leichte Bedenken bzgl. Ausreißer und Linearität.\n",
    "\n",
    "2. **Einfaches Modell (log):** `FeelingSafe ~ Log_Homicides`  \n",
    "   - R² ≈ 0.33–0.35  \n",
    "   - Bessere Linearität über den Wertebereich, geringerer Einfluss extremer Länder.\n",
    "\n",
    "3. **Multiple Modell:** `FeelingSafe ~ Log_Homicides + SocialSupport`  \n",
    "   - R² ≈ 0.49, Adj. R² ≈ 0.46  \n",
    "   - Beide Prädiktoren (log-Mordrate und SocialSupport) sind signifikant.  \n",
    "   - Residuen verhalten sich gut (Normalität, keine dramatische Heteroskedastizität, keine extrem einflussreichen Punkte).\n",
    "\n",
    "\n",
    "Während die einfache Korrelationsanalyse (NB 03) keinen signifikanten Zusammenhang zeigte, enthüllt die multiple Regression (NB 05) die wahre Struktur. Durch die Log-Transformation der Mordrate und die gleichzeitige Betrachtung beider Variablen konnte die Erklärungskraft ($R^2$) massiv gesteigert werden (von fast 0 auf ~49%). Dies zeigt, dass monokausale Erklärungen (nur Mordrate oder nur Support) zu kurz greifen und sich die Effekte gegenseitig maskieren können.\n",
    "\n",
    "\n",
    "**Designentscheidung für das Projekt:**\n",
    "\n",
    "Für **Interpretation** und **Fazit** unseres Projekts verwenden wir das **Multiple-Modell mit `Log_Homicides` und `SocialSupport`** als **finales Arbeitsmodell**.  \n",
    "  - Es bildet sowohl **objektive Gefährdung** als auch **soziales Netz** ab.  \n",
    "  - Es erklärt deutlich mehr Varianz als beide einfachen Modelle.  \n",
    "  - Die Modellannahmen sind hinreichend erfüllt.\n",
    "  - Die log-transformierte Mordrate spiegelt besser wider, dass Unterschiede zwischen „sehr sicher“ und „mäßig unsicher“ subjektiv stärker ins Gewicht fallen als Unterschiede in ohnehin sehr gefährlichen Umgebungen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
